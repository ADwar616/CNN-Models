{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\farha\\\\Desktop\\\\Py\\\\Pencil_shading\"\n",
    "\n",
    "# Define the image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.1,allow_growth=True)\n",
    "# session = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    #Restrict Tensorflow to only allocate 6gb of memory on the first GPU\n",
    "   try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "       [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "   except RuntimeError as e:\n",
    "       #virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3061 images belonging to 5 classes.\n",
      "Found 3061 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GoogLeNet model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the top ones\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - 738s 8s/step - loss: 1.5139 - accuracy: 0.6824 - val_loss: 0.5101 - val_accuracy: 0.8477\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 427s 5s/step - loss: 0.6357 - accuracy: 0.7963 - val_loss: 0.4402 - val_accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 425s 5s/step - loss: 0.5779 - accuracy: 0.8082 - val_loss: 0.3951 - val_accuracy: 0.8645\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 422s 4s/step - loss: 0.5215 - accuracy: 0.8227 - val_loss: 0.3762 - val_accuracy: 0.8773\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 421s 4s/step - loss: 0.4904 - accuracy: 0.8389 - val_loss: 0.3751 - val_accuracy: 0.8809\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 389s 4s/step - loss: 0.4312 - accuracy: 0.8580 - val_loss: 0.2831 - val_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 388s 4s/step - loss: 0.4186 - accuracy: 0.8462 - val_loss: 0.3223 - val_accuracy: 0.8819\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 389s 4s/step - loss: 0.3818 - accuracy: 0.8650 - val_loss: 0.3185 - val_accuracy: 0.8898\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 390s 4s/step - loss: 0.3580 - accuracy: 0.8772 - val_loss: 0.2383 - val_accuracy: 0.9207\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 381s 4s/step - loss: 0.3387 - accuracy: 0.8818 - val_loss: 0.2575 - val_accuracy: 0.9066\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "        epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"GoogleNet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
